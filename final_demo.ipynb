{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Set non-interactive backend\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def process_video_to_video(input_video_path, output_video_path, output_csv_path='landmarks.csv', fps=None):\n",
    "    # Initialize MediaPipe Pose\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=False,\n",
    "                        model_complexity=2,\n",
    "                        smooth_landmarks=True,\n",
    "                        min_detection_confidence=0.5,\n",
    "                        min_tracking_confidence=0.5)\n",
    "\n",
    "    # Open input video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    input_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fps = fps if fps is not None else input_fps if input_fps else 30\n",
    "\n",
    "    # Initialize VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Set up CSV file for saving landmarks\n",
    "    csv_file = open(output_csv_path, 'w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['frame_number', 'landmark_id', 'x', 'y', 'z', 'visibility'])\n",
    "\n",
    "    # Set up Matplotlib figure\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Initialize progress tracking\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames, desc=\"Processing video\")\n",
    "    frame_number = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process frame with MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "\n",
    "        # Clear previous plot\n",
    "        ax.cla()\n",
    "        ax.set_xlim3d(-1, 1)\n",
    "        ax.set_ylim3d(-1, 1)\n",
    "        ax.set_zlim3d(-1, 1)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "\n",
    "        if results.pose_world_landmarks:\n",
    "            # Plot landmarks\n",
    "            plot_world_landmarks(plt, ax, results.pose_world_landmarks)\n",
    "            \n",
    "            # Save landmarks to CSV\n",
    "            for idx, landmark in enumerate(results.pose_world_landmarks.landmark):\n",
    "                csv_writer.writerow([\n",
    "                    frame_number,\n",
    "                    idx,\n",
    "                    landmark.x,\n",
    "                    landmark.y,\n",
    "                    landmark.z,\n",
    "                    landmark.visibility\n",
    "                ])\n",
    "        else:\n",
    "            # Write empty entry for missing detection\n",
    "            csv_writer.writerow([frame_number, -1, None, None, None, None])\n",
    "\n",
    "        # Convert plot to image\n",
    "        fig.canvas.draw()\n",
    "        pose_img = np.array(fig.canvas.buffer_rgba())\n",
    "        pose_img = cv2.cvtColor(pose_img, cv2.COLOR_RGBA2BGR)\n",
    "        pose_img = cv2.resize(pose_img, (width, height))\n",
    "\n",
    "        # Overlay visualization\n",
    "        combined_frame = cv2.addWeighted(frame, 0.7, pose_img, 0.3, 0)\n",
    "        video_writer.write(combined_frame)\n",
    "\n",
    "        frame_number += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Cleanup resources\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    csv_file.close()\n",
    "    plt.close(fig)\n",
    "    pbar.close()\n",
    "    print(f\"Processed video saved to: {output_video_path}\")\n",
    "    print(f\"Landmarks data saved to: {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_world_landmarks(\n",
    "    plt,\n",
    "    ax,\n",
    "    landmarks,\n",
    "    visibility_th=0.5,\n",
    "):\n",
    "    landmark_point = []\n",
    "\n",
    "    for index, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_point.append(\n",
    "            [landmark.visibility, (landmark.x, landmark.y, landmark.z)])\n",
    "\n",
    "    face_index_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    right_arm_index_list = [11, 13, 15, 17, 19, 21]\n",
    "    left_arm_index_list = [12, 14, 16, 18, 20, 22]\n",
    "    right_body_side_index_list = [11, 23, 25, 27, 29, 31]\n",
    "    left_body_side_index_list = [12, 24, 26, 28, 30, 32]\n",
    "    shoulder_index_list = [11, 12]\n",
    "    waist_index_list = [23, 24]\n",
    "\n",
    "    # 顔\n",
    "    face_x, face_y, face_z = [], [], []\n",
    "    for index in face_index_list:\n",
    "        point = landmark_point[index][1]\n",
    "        face_x.append(point[0])\n",
    "        face_y.append(point[2])\n",
    "        face_z.append(point[1] * (-1))\n",
    "\n",
    "    # 右腕\n",
    "    right_arm_x, right_arm_y, right_arm_z = [], [], []\n",
    "    for index in right_arm_index_list:\n",
    "        point = landmark_point[index][1]\n",
    "        right_arm_x.append(point[0])\n",
    "        right_arm_y.append(point[2])\n",
    "        right_arm_z.append(point[1] * (-1))\n",
    "\n",
    "    # 左腕\n",
    "    left_arm_x, left_arm_y, left_arm_z = [], [], []\n",
    "    for index in left_arm_index_list:\n",
    "        point = landmark_point[index][1]\n",
    "        left_arm_x.append(point[0])\n",
    "        left_arm_y.append(point[2])\n",
    "        left_arm_z.append(point[1] * (-1))\n",
    "\n",
    "    # 右半身\n",
    "    right_body_side_x, right_body_side_y, right_body_side_z = [], [], []\n",
    "    for index in right_body_side_index_list:\n",
    "        point = landmark_point[index][1]\n",
    "        right_body_side_x.append(point[0])\n",
    "        right_body_side_y.append(point[2])\n",
    "        right_body_side_z.append(point[1] * (-1))\n",
    "\n",
    "    # 左半身\n",
    "    left_body_side_x, left_body_side_y, left_body_side_z = [], [], []\n",
    "    for index in left_body_side_index_list:\n",
    "        point = landmark_point[index][1]\n",
    "        left_body_side_x.append(point[0])\n",
    "        left_body_side_y.append(point[2])\n",
    "        left_body_side_z.append(point[1] * (-1))\n",
    "\n",
    "    # 肩\n",
    "    shoulder_x, shoulder_y, shoulder_z = [], [], []\n",
    "    for index in shoulder_index_list:\n",
    "        point = landmark_point[index][1]\n",
    "        shoulder_x.append(point[0])\n",
    "        shoulder_y.append(point[2])\n",
    "        shoulder_z.append(point[1] * (-1))\n",
    "\n",
    "    # 腰\n",
    "    waist_x, waist_y, waist_z = [], [], []\n",
    "    for index in waist_index_list:\n",
    "        point = landmark_point[index][1]\n",
    "        waist_x.append(point[0])\n",
    "        waist_y.append(point[2])\n",
    "        waist_z.append(point[1] * (-1))\n",
    "            \n",
    "    ax.cla()\n",
    "    ax.set_xlim3d(-1, 1)\n",
    "    ax.set_ylim3d(-1, 1)\n",
    "    ax.set_zlim3d(-1, 1)\n",
    "\n",
    "    ax.scatter(face_x, face_y, face_z)\n",
    "    ax.plot(right_arm_x, right_arm_y, right_arm_z)\n",
    "    ax.plot(left_arm_x, left_arm_y, left_arm_z)\n",
    "    ax.plot(right_body_side_x, right_body_side_y, right_body_side_z)\n",
    "    ax.plot(left_body_side_x, left_body_side_y, left_body_side_z)\n",
    "    ax.plot(shoulder_x, shoulder_y, shoulder_z)\n",
    "    ax.plot(waist_x, waist_y, waist_z)\n",
    "    \n",
    "    plt.pause(.001)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model to e:\\ml_shiz\\hackenza_quidich\\quidich_env\\lib\\site-packages\\mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:   0%|          | 0/506 [00:00<?, ?it/s]C:\\Users\\Dhruv\\AppData\\Local\\Temp\\ipykernel_4252\\1828743677.py:90: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.pause(.001)\n",
      "Processing video: 100%|██████████| 506/506 [02:18<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video saved to: output_new_2.mp4\n",
      "Landmarks data saved to: cropped_landmarks_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_video_to_video(r\"E:\\ml_shiz\\hackenza_quidich\\Quidich-HACKATHON-25\\2_crop.mp4\", \"output_new_2.mp4\", \"cropped_landmarks_2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing video:   0%|          | 0/506 [00:00<?, ?it/s]C:\\Users\\Dhruv\\AppData\\Local\\Temp\\ipykernel_4252\\1828743677.py:90: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.pause(.001)\n",
      "Processing video: 100%|██████████| 506/506 [02:05<00:00,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed video saved to: output_new_1.mp4\n",
      "Landmarks data saved to: cropped_landmarks_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_video_to_video(r\"E:\\ml_shiz\\hackenza_quidich\\Quidich-HACKATHON-25\\1_crop.mp4\", \"output_new_1.mp4\", \"cropped_landmarks_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
